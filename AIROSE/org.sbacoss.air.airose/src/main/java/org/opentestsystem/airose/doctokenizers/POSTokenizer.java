/*******************************************************************************
 * Copyright (c) 2013 American Institutes for Research
 * 
 * This file is part of AIROSE.
 * 
 * AIROSE is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 2 of the License, or
 * (at your option) any later version.
 * 
 * AIROSE is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 * 
 * You should have received a copy of the GNU General Public License
 * along with AIROSE.  If not, see <http://www.gnu.org/licenses/>.
 ******************************************************************************/
package org.opentestsystem.airose.doctokenizers;

import java.util.ArrayList;
import java.util.List;
import java.util.Stack;

import opennlp.tools.parser.Parse;

import org.opentestsystem.airose.common.abstractdocument.AbstractDocTokenizers;
import org.opentestsystem.airose.common.abstractdocument.AbstractDocument;
import org.opentestsystem.airose.common.abstractdocument.AbstractToken;
import org.opentestsystem.airose.common.abstractdocument.DocTokenizationException;
import org.opentestsystem.airose.common.abstractdocument.EnumPOS;
import org.opentestsystem.airose.document.TokenFactory;

/*
 * This class tokenizes based on the OpenNLP parse trees.
 */
public class POSTokenizer extends AbstractDocTokenizers
{

  public POSTokenizer (AbstractDocument doc) {
    super (doc);
  }

  public boolean tokenizeDocument () throws DocTokenizationException {
    AbstractDocument doc = getDocument ();
    List<AbstractToken> tokensToBeAdded = convertToPOSList (doc, doc.getParse ());
    if (tokensToBeAdded != null && tokensToBeAdded.size () != 0) {
      List<AbstractToken> existingTokens = doc.getListOfTokens ();
      existingTokens.addAll (tokensToBeAdded);
    }
    return true;
  }

  public static List<AbstractToken> convertToPOSList (AbstractDocument doc, Parse parses[]) {

    List<AbstractToken> listOfWordPOS = new ArrayList<AbstractToken> ();

    if (parses != null && parses.length > 0) {
      for (int counter1 = 0; counter1 < parses.length; ++counter1) {
        Parse parse = parses[counter1];
        Stack<Parse> st = new Stack<Parse> ();
        st.add (parse);
        while (!st.isEmpty ()) {
          parse = st.pop ();
          if (parse.getChildren () != null && parse.getChildren ().length > 0) {

            // push it in reverse order.
            for (int counter2 = parse.getChildren ().length - 1; counter2 > -1; --counter2) {
              st.push (parse.getChildren ()[counter2]);
            }
            continue;
          }

          // else if leaf level node then save it.
          String subtext = parse.getText ().substring (parse.getSpan ().getStart (), parse.getSpan ().getEnd ());
          AbstractToken token = TokenFactory.getInstance (doc);
          token.setToken (subtext);
          try {
            token.setPOS (EnumPOS.valueOf (parse.getParent ().getType ()));
          } catch (Exception exp) {
            /* the part-of-speech tag is not know. */
            token.setPOS (EnumPOS.NOT_AVAILABLE);
          }
          listOfWordPOS.add (token);
        }
      }

    }

    return listOfWordPOS;
  }

}
