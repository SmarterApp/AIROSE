/*******************************************************************************
 * Copyright (c) 2013 American Institutes for Research
 * 
 * This file is part of AIROSE.
 * 
 * AIROSE is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 2 of the License, or
 * (at your option) any later version.
 * 
 * AIROSE is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 * 
 * You should have received a copy of the GNU General Public License
 * along with AIROSE.  If not, see <http://www.gnu.org/licenses/>.
 ******************************************************************************/
package org.opentestsystem.airose.validation.stats;

import java.io.FileNotFoundException;
import java.io.PrintStream;
import java.util.HashMap;
import java.util.Hashtable;
import java.util.Iterator;
import java.util.List;

import org.apache.log4j.Logger;
import org.opentestsystem.airose.common.abstractdocument.AbstractDocument;
import org.opentestsystem.airose.db.entities.EnumScoringStatus;
import org.opentestsystem.airose.linear.Matrix;
import org.opentestsystem.airose.regression.AbstractDocumentStats;
import org.opentestsystem.airose.utilities.LoggerUtil;

public class PercentageExactMatchCalculator extends AbstractStatsProcessor
{

  private static final Logger                       LOGGER              = Logger.getLogger (PercentageExactMatchCalculator.class.getName ());

  private HashMap<Integer, Integer>                 mDiffMap            = new HashMap<Integer, Integer> ();
  // keep track of all aggregate columns.
  // todo : we should keep track of score in this map rather than mDiffMap.
  private HashMap<String, HashMap<String, Integer>> mAggregateValuesMap = new HashMap<String, HashMap<String, Integer>> ();

  private PrintStream                               mValidationStatsPrn = null;
  // for how many validation records did we encounter a null document vector as
  // the
  // response was inadequate.
  private int                                       mNotEnoughDataStats = 0;

  public PercentageExactMatchCalculator (String outputFolder) {
    super (outputFolder);
  }

  protected void processDocumentStat (AbstractDocumentStats stat) {
    if (stat == null)
      return;
    AbstractDocument doc = stat.getDocument ();
    int newScoreRoundedToNearestInt = (int) (Math.round (stat.getNewScore ()));
    int oldScoreRoundedToNearestInt = (int) (Math.round (doc.getScore ()));
    int diff = newScoreRoundedToNearestInt - oldScoreRoundedToNearestInt;

    if (!mDiffMap.containsKey (diff)) {
      mDiffMap.put (diff, 0);
    }

    mDiffMap.put (diff, mDiffMap.get (diff) + 1);

    String bookId = doc.getColumnValue ("BookId").toString ();
    String grade = doc.getColumnValue ("Grade").toString ();
    String form = doc.getColumnValue ("Form").toString ();
    String imaginid = doc.getColumnValue ("Imaginid").toString ();
    String item = doc.getColumnValue ("Item").toString ();
    String score1 = doc.getColumnValue ("Score1").toString ();
    String score2 = doc.getColumnValue ("Score2").toString ();
    String outputFileName = doc.getColumnValue ("OutputFilename").toString ();
    String response = doc.getOriginalResponse ();
    StringBuilder statusLine = new StringBuilder ();
    // first add the regular data.
    statusLine.append (String.format ("%s, %d, %d, %s, %s, %s, %s, %s, %s, %s, %s", doc.getDocId (), oldScoreRoundedToNearestInt, newScoreRoundedToNearestInt, bookId, grade, form, imaginid, item,
        score1, score2, "" + doc.getWordCount ()));
    // now add data for the specific model.
    List<String> additionalDataPointElements = stat.getDescriptiveHeader ();
    Hashtable<String, String> additionalDataPoints = stat.getAdditionalDataPoints ();
    for (int counter1 = 0; counter1 < additionalDataPointElements.size (); ++counter1) {
      String dataPointElement = additionalDataPointElements.get (counter1);
      String dataPoint = additionalDataPoints.get (dataPointElement);
      if (dataPoint == null)
        statusLine.append (", N/A");
      else
        statusLine.append (", " + dataPoint);
    }
    // append the scoring status message
    statusLine.append (", " + stat.getScoringMessage ().toString ());

    Iterator<String> columnsInDoc = doc.getColumnIterator ();
    while (columnsInDoc.hasNext ()) {
      String key = columnsInDoc.next ();
      statusLine.append (", " + doc.getColumnValue (key));
    }

    statusLine.append (", " + outputFileName);
    statusLine.append (", " + response);

    mValidationStatsPrn.println (statusLine.toString ());

    if (stat.getScoringMessage () == EnumScoringStatus.NOT_ENOUGH_DATA)
      ++mNotEnoughDataStats;

    addToAggregateMap (stat.getDocument ());
  }

  protected void preProcessDocumentStats (@SuppressWarnings ("rawtypes") List stats) throws FileNotFoundException {
    mValidationStatsPrn = new PrintStream (getOutputFolder () + "/validationStats.csv");

    StringBuilder strn = new StringBuilder ("Id, Old Score(Score1) , New (Rounded) Score, BookId, Grade, Form, ImaginId, Item, Score1, Score2, WordCount");

    AbstractDocumentStats firstStat = getFirstNonEmptyStats (stats);
    if (firstStat != null) {
      List<String> additionalHeaderElements = firstStat.getDescriptiveHeader ();
      for (int counter1 = 0; counter1 < additionalHeaderElements.size (); ++counter1) {
        strn.append ("," + additionalHeaderElements.get (counter1));
      }
    }
    // append the machine scoring status
    strn.append (", New Machine Scoring Status");

    // append all columns from the document.
    AbstractDocument doc = getFirstNonEmptyDocument (stats);
    // just a precautionary check.
    if (doc != null) {
      Iterator<String> columnsInDoc = doc.getColumnIterator ();
      while (columnsInDoc.hasNext ()) {
        String key = columnsInDoc.next ();
        strn.append (", " + key);
      }
    }
    // we want to put the response at the end because it may have commas that
    // may mess up our pretty CSV file.
    strn.append (", OutputfileName, Response");
    mValidationStatsPrn.println (strn.toString ());
  }

  @SuppressWarnings ("unchecked")
  protected void postProcessDocumentStats (@SuppressWarnings ("rawtypes") List stats) throws FileNotFoundException {
    // close the file we wrote into all the document information.
    mValidationStatsPrn.close ();
    PrintStream prn = new PrintStream (getOutputFolder () + "/scoreDiffs.csv");
    prn.println ("====================Difference Spread=========================");
    prn.println ("Total Documents: " + stats.size ());
    prn.println ("\n\n\n");
    prn.println ("Difference in Scores, Count");
    Iterator<Integer> diffIterator = mDiffMap.keySet ().iterator ();
    while (diffIterator.hasNext ()) {
      int diff = diffIterator.next ();
      prn.println (String.format ("%d, %d", diff, mDiffMap.get (diff)));
    }
    prn.println ("====================Exception cases(in which case gets a score of 0)=========================");
    prn.println (EnumScoringStatus.NOT_ENOUGH_DATA.toString () + ", " + mNotEnoughDataStats);

    prn.println ("====================Other document aggregate data=========================");
    Iterator<String> aggregateColumnNames = mAggregateValuesMap.keySet ().iterator ();
    while (aggregateColumnNames.hasNext ()) {
      String aggregateColumnName = aggregateColumnNames.next ();
      prn.println ("Map for " + aggregateColumnName);
      HashMap<String, Integer> mapOfValuesForColumn = mAggregateValuesMap.get (aggregateColumnName);
      Iterator<String> values = mapOfValuesForColumn.keySet ().iterator ();
      while (values.hasNext ()) {
        String value = values.next ();
        prn.println (String.format ("%s, %d", value, mapOfValuesForColumn.get (value)));
      }
      prn.println ("");
    }

    prn.close ();

    printDocumentVectors (stats);
  }

  private void printDocumentVectors (List<AbstractDocumentStats> stats) throws FileNotFoundException {
    AbstractDocumentStats firstStat = getMaxNumberOfColumnsInDocVector (stats);
    int numberOfRows = 0;
    if (firstStat != null) {
      Matrix m = firstStat.getDocument ().getRegressionInputDocVector ();
      numberOfRows = m.rows ();
    }

    PrintStream docVectorsPrn = new PrintStream (getOutputFolder () + "/validationDocVectors.csv");
    StringBuilder strn = new StringBuilder ("");
    strn.append ("docId<string>, human score, calculated score,");
    for (int counter1 = 0; counter1 < numberOfRows; ++counter1) {
      strn.append (String.format ("x[%d],", counter1));
    }
    docVectorsPrn.println (strn.toString ());

    for (AbstractDocumentStats stat : (List<AbstractDocumentStats>) stats) {

      Matrix m = stat.getDocument ().getRegressionInputDocVector ();
      if (m != null) {
        strn = new StringBuilder (String.format ("%1$s, %2$f, %3$f,", stat.getDocument ().getDocId (), stat.getDocument ().getScore (), stat.getNewScore ()));
        for (int counter1 = 0; counter1 < m.rows (); ++counter1) {
          strn.append (String.format ("%f,", m.get (counter1, 0)));
        }
        docVectorsPrn.println (strn.toString ());
      }
    }
    docVectorsPrn.close ();
  }

  private AbstractDocumentStats getFirstNonEmptyStats (@SuppressWarnings ("rawtypes") List stats) {
    for (Object obj : stats) {
      if (obj == null)
        continue;
      return (AbstractDocumentStats) obj;
    }
    return null;
  }

  // TODO hack
  private AbstractDocumentStats getMaxNumberOfColumnsInDocVector (List<AbstractDocumentStats> stats) {
    AbstractDocumentStats firstStat = null;

    int max = 0;
    for (AbstractDocumentStats stat : (List<AbstractDocumentStats>) stats) {
      try {
        if (stat.getDocument ().getRegressionInputDocVector ().rows () > max)
          firstStat = stat;
      } catch (Exception exp) {
        LoggerUtil.warning (LOGGER, "Document regression input vector is empty. Possibly there was an exception processing the document.");
      }

    }
    return firstStat;
  }

  private AbstractDocument getFirstNonEmptyDocument (@SuppressWarnings ("rawtypes") List stats) {
    for (Object obj : stats) {
      if (obj == null)
        continue;
      return ((AbstractDocumentStats) obj).getDocument ();
    }
    return null;
  }

  private void addToAggregateMap (AbstractDocument doc) {
    Iterator<String> aggregateColumnKeys = doc.getAggregateKeysetIterator ();
    while (aggregateColumnKeys.hasNext ()) {
      String key = aggregateColumnKeys.next ();
      // get existing mapping.
      HashMap<String, Integer> existingMap = mAggregateValuesMap.get (key);
      if (existingMap == null) {
        existingMap = new HashMap<String, Integer> ();
        mAggregateValuesMap.put (key, existingMap);
      }

      // lets get the document value for the column.
      String value = doc.getColumnValue (key);
      int countForValue = 0;
      if (existingMap.containsKey (value)) {
        countForValue = existingMap.get (value);
      }
      ++countForValue;
      existingMap.put (value, countForValue);
    }
  }
}
