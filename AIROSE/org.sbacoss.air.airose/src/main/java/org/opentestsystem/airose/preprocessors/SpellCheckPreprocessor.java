/*******************************************************************************
 * Copyright (c) 2013 American Institutes for Research
 * 
 * This file is part of AIROSE.
 * 
 * AIROSE is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 2 of the License, or
 * (at your option) any later version.
 * 
 * AIROSE is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 * 
 * You should have received a copy of the GNU General Public License
 * along with AIROSE.  If not, see <http://www.gnu.org/licenses/>.
 ******************************************************************************/
package org.opentestsystem.airose.preprocessors;

import java.util.HashMap;

import org.opentestsystem.airose.common.abstractdocument.AbstractDocProcessors;
import org.opentestsystem.airose.common.abstractdocument.AbstractDocument;
import org.opentestsystem.airose.common.abstractdocument.AbstractResource;
import org.opentestsystem.airose.common.abstractdocument.DocProcessorException;
import org.opentestsystem.airose.languagetool.LanguageTool;
import org.opentestsystem.airose.languagetool.Mistakes;
import org.opentestsystem.airose.resources.SpellCheckResource;

/*
 * We do an initial pass on the data - this is required primarily for training
 * data.
 */
public class SpellCheckPreprocessor extends AbstractDocProcessors
{
  public SpellCheckPreprocessor (AbstractDocument doc) {
    super (doc);
  }

  /*
   * @return true if the processing should continue to other processors in the
   * chain. false otherwise.
   */
  public boolean processDocument (HashMap<String, AbstractResource> resourceMap) throws DocProcessorException {

    SpellCheckResource resource = (SpellCheckResource) resourceMap.get (SpellCheckResource.class.getName ());
    AbstractDocument doc = getDocument ();
    String response = doc.getModifiedResponse ();

    try {
      LanguageTool languageTool = LanguageTool.getInstanceForDefaultLanguage ();
      Mistakes mistakes = languageTool.check (response);

      // now tokenize
      String[] tokens = response.split ("[\\s+]|[0-9]|\"");
      doc.setWordCount (tokens.length);
      // for each token check if it exists in the mistake.
      // note: this strictly depends on the fact that Mistakes only
      // support lookups on spelling errors.
      for (String token : tokens) {
        if (!mistakes.isContextInMistakesList (token) && token.length () > 1) {
          // add it to the list of valid words only if
          // not a number and not a single character letter.
          try {
            Double.parseDouble (token);
          } catch (NumberFormatException exp) {
            // if the word contains
            resource.addToPreviouslyEncounteredWords (token.toLowerCase ());
          }
        }
      }

    } catch (Exception exp) {
      throw new DocProcessorException (exp);
    }

    return true;
  }

  public static void main (String[] args) {
    String[] tokens = "x'y   z98\"".split ("[\\s+]|[0-9]|\"");
    for (String token : tokens) {
      System.err.println (token);
    }
  }
}
