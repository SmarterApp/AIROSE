package org.air.essayscorer.mains;

import edu.ucla.sspace.common.ArgOptions;
import edu.ucla.sspace.matrix.Matrix;
import org.air.essayscorer.utilities.LoggerUtil;

import java.io.IOException;
import java.sql.SQLException;
import java.util.logging.Logger;
import java.io.File;

import org.air.essayscorer.common.abstractdocument.AbstractDocument;
import org.air.essayscorer.common.config.AbstractConfiguration;
import org.air.essayscorer.common.config.ConfigurationFactory;
import org.air.essayscorer.common.config.ConfigurationFactory.ConfigurationType;
import org.air.essayscorer.common.config.TrainerConfiguration;
import org.air.essayscorer.common.config.UninitializedException;
import org.air.essayscorer.db.accessors.DocumentQualityAccessor;
import org.air.essayscorer.db.accessors.MatrixAccessor;
import org.air.essayscorer.db.accessors.ModelAccessor;
import org.air.essayscorer.db.accessors.ModelEntryAccessor;
import org.air.essayscorer.db.accessors.PreviouslySeenWordsAccessor;
import org.air.essayscorer.db.accessors.ReadOnlyModeException;
import org.air.essayscorer.db.accessors.TermAccessor;
import org.air.essayscorer.db.accessors.UniqueResultException;
import org.air.essayscorer.db.entities.EnumRegressionModel;
import org.air.essayscorer.db.entities.MatrixType;
import org.air.essayscorer.db.entities.Model;
import org.air.essayscorer.db.session.DBSession;
import org.air.essayscorer.db.session.DBSessionFactory;
import org.air.essayscorer.db.session.SessionException;
import org.air.essayscorer.docquality.DocumentQualityLoader;
import org.air.essayscorer.document.DocumentFactory;
import org.air.essayscorer.regression.AbstractModel;
import org.air.essayscorer.regression.EmptyModel;
import org.air.essayscorer.regression.EmptyModelDocumentStats;
import org.air.essayscorer.regression.RegressionModeller;
import org.air.essayscorer.regression.RegressionModellingException;
import org.air.essayscorer.resources.SpellCheckResource;
import org.air.essayscorer.sspace.LSANotInitializedException;
import org.air.essayscorer.sspace.ReducedDimensionMapper;
import org.air.essayscorer.sspace.TermDimensionMap;
import org.air.essayscorer.sspace.TrainEssayScorerLSA;
import org.air.essayscorer.validation.stats.AverageWordCountStats;
import org.air.essayscorer.validation.stats.StatsProcessor;

import java.io.BufferedReader;
import java.io.FileReader;

public class EssayScorerTrainer extends AbstractMain {

	private static final Logger LOGGER = Logger
			.getLogger(EssayScorerTrainer.class.getName());
	/*
	 * the SemanticSpace for this training. currently we only support LSA.
	 */
	private TrainEssayScorerLSA mLSA = null;
	private TermDimensionMap mDimensionMapper = null;
	/*
	 * keep track of various document quality attributes.
	 */
	private DocumentQualityLoader mDocQualityAssessor = null;

	public EssayScorerTrainer(String argv[]) {
		super(argv);
	}

	public static void main(String argv[]) {
		EssayScorerTrainer trainer = new EssayScorerTrainer(argv);
		trainer.run();
	}

	/*
	 * Since we are going to build a model, there is no need to load anything
	 * from the database. (non-Javadoc)
	 * 
	 * @see org.air.essayscorer.mains.AbstractMain#initialization()
	 */
	protected boolean initialization() throws UninitializedException,
			SessionException {
		return true;
	}

	/*
	 * (non-Javadoc)
	 * 
	 * @see org.air.essayscorer.mains.AbstractMain#customRun()
	 */
	protected void customRun() throws UninitializedException, IOException {

		TrainerConfiguration runConfig = (TrainerConfiguration) ConfigurationFactory
				.getConfiguration();

		String modelId = getModelId();
		String essayId = getEssayId();
		String scoreType = getScoreType();

		try {
			DBSession session = DBSessionFactory.getInstance().getSession(
					this.hashCode());
			ModelAccessor modelAccessor = new ModelAccessor(session);

			Model md = modelAccessor.getModel(modelId, essayId, scoreType);
			session.closeSession(this.hashCode());

			if (md != null)
				throw new UninitializedException(
						String.format(
								"A model for  Model Id %s, Essay Id %s and Score Type %s already exists. Atleast one  of the three values have to be unique. Aborting!",
								modelId, essayId, scoreType));
		} catch (SessionException sqlExp) {
			sqlExp.printStackTrace();
			LoggerUtil.severe(LOGGER,
					"Exception creating session. Message: %s. Exit.",
					sqlExp.getMessage());
			return;
		} catch (UniqueResultException uniqueResultExp) {
			uniqueResultExp.printStackTrace();
			LoggerUtil.severe(LOGGER, uniqueResultExp.getMessage());
			return;
		}

		EnumRegressionModel regressionModel = runConfig.getRegressionModel();
		String directoryName = getInputFolderName();

		String outputFolder = getOutputFolder();
		createFolder(outputFolder);
		//create a stat processor so that we can extract aggregate values e.g. word count.
		//we do not have a model yet so we will have to use EmptyModel as a placeholder for our model
		StatsProcessor statProcessor = new StatsProcessor(outputFolder, new EmptyModel());
		statProcessor.addToListOfStatProcessors(new AverageWordCountStats(outputFolder));
		// hack!!! step 0: do a first pass and build the resources. we need to
		// redo this loop.
		File directory = new File(directoryName);
		String[] listOfFiles = directory.list();
		for (String file : listOfFiles) {
			try {
				String fileName = directoryName + "/" + file;
				BufferedReader reader = new BufferedReader(new FileReader(
						fileName));
				preProcessDocument(fileName, reader, essayId, statProcessor);
			} catch (IOException exp) {
				exp.printStackTrace();
				LoggerUtil.severe(LOGGER,
						"Exception processing files for training. Message: %s",
						exp.getMessage());
			}
		}
		//we will print out some statistics about the training documents that do not require a model.
		statProcessor.process();
		
		//now make the spell check resource readonly.
		SpellCheckResource resource = (SpellCheckResource) getResources().get(SpellCheckResource.class.getName());
		resource.setReadOnly(true);
		
		// step 1: set the semantic space. 
		mDimensionMapper = new TermDimensionMap();
		mDocQualityAssessor = DocumentQualityLoader.getInstance();
		mLSA = new TrainEssayScorerLSA(essayId, modelId, scoreType,
				mDimensionMapper, getResources(), mDocQualityAssessor);
	

		// step 2: get the list of files that we need to train on.
		directory = new File(directoryName);
		listOfFiles = directory.list();
		for (String file : listOfFiles) {
			try {
				String fileName = directoryName + "/" + file;
				BufferedReader reader = new BufferedReader(new FileReader(
						fileName));
				mLSA.setFileBeingCurrentlyProcessed(fileName);
				mLSA.processDocument(reader);

			} catch (IOException exp) {
				exp.printStackTrace();
				LoggerUtil.severe(LOGGER,
						"Exception processing files for training. Message: %s",
						exp.getMessage());
			}
		}

		// step 3. Process space
		mLSA.processSpace();

		// step 4: Save the semantic space, the matrices and ``the term
		// dimension
		// information.
		// first lets save the semantic space as that is the easiest one.
		
		File outputFile = new File(outputFolder + "/" + essayId + ".sspace");
		saveSSpace(mLSA, outputFile);

		/*
		 * todo: load these from db instead once we have saved them.
		 */
		Model md = null;
		Matrix[] usv = null;

		try {
			DBSession session = DBSessionFactory.getInstance().getSession(
					this.hashCode());
			ModelAccessor modelAccessor = new ModelAccessor(session);
			TermAccessor termAccessor = new TermAccessor(session);
			MatrixAccessor matrixAccessor = new MatrixAccessor(session);

			// first save the model.
			md = new Model(modelId, essayId, scoreType, regressionModel,
					mLSA.getNumberOfDimensionsInReducedSpace());
			md = modelAccessor.insertNewModel(md);
			// save the term index.
			termAccessor.saveTermIndex(mDimensionMapper, md);
			// save the three matrices.
			usv = mLSA.getUSV();
			matrixAccessor.saveMatricex(usv[0], MatrixType.Matrix_U, md);
			matrixAccessor.saveMatricex(usv[1], MatrixType.Matrix_S, md);
			matrixAccessor.saveMatricex(usv[2], MatrixType.Matrix_V, md);
			/*
			 * we have to adjust the dimensions of the document quality
			 * attributes that we will be using.
			 */

			DocumentQualityAccessor docQualityAccessor = new DocumentQualityAccessor(
					session);
			mDocQualityAssessor.adjustModelAndDimensions(
					mLSA.getNumberOfDimensionsInReducedSpace(), md);
			mDocQualityAssessor.saveToDB(docQualityAccessor);
			mDocQualityAssessor.saveToFolder(getOutputFolder());
			//save the resources.
			//first: spell check resource.
			PreviouslySeenWordsAccessor previouslySeenWordAccessor = new PreviouslySeenWordsAccessor(session);
			resource.saveToDB(previouslySeenWordAccessor, md);
			
			session.closeSession(this.hashCode());

		} catch (SessionException sqlExp) {
			sqlExp.printStackTrace();
			LoggerUtil.severe(LOGGER,
					"Exception saving data to db. Message: %s. Exit.",
					sqlExp.getMessage());
			return;
		}
		// on all other exceptions we need to mark the model as useless in the
		// database.
		catch (ReadOnlyModeException readOnlyExp) {
			readOnlyExp.printStackTrace();
			LoggerUtil.severe(LOGGER,
					"Exception saving data to db. Message: %s. Exit.",
					readOnlyExp.getMessage());
			return;
		} catch (LSANotInitializedException lsaExp) {
			lsaExp.printStackTrace();
			LoggerUtil.severe(LOGGER,
					"Exception saving data to db. Message: %s. Exit.",
					lsaExp.getMessage());
			return;
		}

		// step 5: create the model.
		// during this step we will set the dimension mapper to readOnly. we
		// will also
		// need to set it to readonly throughout scoring/validation.
		mDimensionMapper.setReadOnly(true);
		try {
			DBSession session = DBSessionFactory.getInstance().getSession(
					this.hashCode());
			ModelEntryAccessor modelEntryAccessor = new ModelEntryAccessor(
					session);
			MatrixAccessor matrixAccessor = new MatrixAccessor(session);

			ReducedDimensionMapper dimensionReMapper = new ReducedDimensionMapper(
					modelId, essayId, scoreType, usv, mDimensionMapper);
			RegressionModeller modeller = new RegressionModeller(modelId,
					essayId, scoreType, dimensionReMapper, mDocQualityAssessor,
					getResources());

			try {
				AbstractModel outputModel = modeller
						.runRegressionModelling(directoryName);
				outputModel.saveToDatabase(modelEntryAccessor, matrixAccessor,
						md, outputFolder);
			} catch (RegressionModellingException modellingExp) {
				modellingExp.printStackTrace();
				LoggerUtil.severe(LOGGER,
						"Exception generating model. Message: %s.",
						modellingExp.getMessage());
			}
			session.closeSession(this.hashCode());
		}

		catch (SessionException sqlExp) {
			sqlExp.printStackTrace();
			LoggerUtil.severe(LOGGER,
					"Exception saving model data to db. Message: %s. Exit.",
					sqlExp.getMessage());
		}

		// that's it. run validation etc in separate class.
	}

	protected void finish() throws UninitializedException, IOException,
			SessionException {
		// nothing to do here.
	}

	/*
	 * (non-Javadoc)
	 * 
	 * @see org.air.essayscorer.mains.AbstractMain#getConfigurationType()
	 * 
	 * Returns a constant value of ConfigurationType.TRAINER.
	 */
	protected ConfigurationType getConfigurationType() {
		return ConfigurationType.TRAINER;
	}

	/*
	 * just print usage options.
	 */
	protected void usage() {
		System.out.println("usage: java " + this.getClass().getName() + " "
				+ mRunOptions.prettyPrint());
	}

	protected void setupAdditionalOptions() {
		// Add input folder.
		addInputFolderOption();
		// Add option for output folder. the semantic space file will
		// saved to this folder along with other possible files.
		addOutputFolderOption();
	}

	private void preProcessDocument(String fileName, BufferedReader document,
			String essayId, StatsProcessor statProcessor) {
		String line = null;
		try {
			while ((line = document.readLine()) != null) {
				try {
					// Each line consists of a score and a response separated by
					// a comma. First process and tokenize the document.
					AbstractDocument doc = DocumentFactory.getDocument(
							fileName, line, essayId, -1);
					// process
					doc.invokeDocumentPreprocessors(getResources());
					
					statProcessor.addToDocumentStats(new EmptyModelDocumentStats(doc));
				} catch (Exception exp) {
					LoggerUtil
							.severe(LOGGER,
									"Exception invoking docProcessors/docTokenizers on \"%s\". Message: %s",
									line, exp.getMessage());
				}
			}

			// close the document.
			document.close();
		} catch (IOException exp) {
			// do nothing.
		}
	}

}
